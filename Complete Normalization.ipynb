{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7531d3ad-8123-4f11-878d-f6d16f0d2a85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd #analyzing, cleaning, and storing data \n",
    "import io\n",
    "import os \n",
    "import pyarrow.parquet as pq #parquet specific analysis \n",
    "import numpy as np\n",
    "import stats\n",
    "import fastparquet #make sure that this is installed in your anaconda environment\n",
    "from scipy import stats\n",
    "from scipy.stats import median_abs_deviation\n",
    "from scipy.stats import zscore\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.datasets import make_classification\n",
    "from feature_engine.selection import DropCorrelatedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b037379-2df2-4b9b-b64a-d085ee9898b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#call the folder with multiple parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3358e28d-0675-45b0-9fa6-9ba2d8c92ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# the r below must be placed before the file to indicate that it is a raw string - // are not escape sequences but rather characters \n",
    "data_directory = Path(r'C:\\Users\\abbyk\\OneDrive - Northeastern University\\Documents\\Capstone\\Multiple Parquets for Practice\\B040103a.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0153d8-d533-4d97-8aa9-d240f5e99eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concatenate multiple parquet files into one cvs file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee556802-17f7-4ab4-bdbb-cd7ec1f67549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full_df = pd.concat(\n",
    "#    pd.read_parquet(parquet_file)\n",
    "#    for parquet_file in data_directory.glob('*.parquet') #.glob searches for only parquets\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eb4f2d2-233e-4efc-b0a0-54ef63cc4b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_parquet(data_directory, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29a85993-e85c-4a43-8bc7-c0863ee9078d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b0b7040-7663-4927-873c-3ea0c2a11f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full_df.to_csv('original_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9ea3ab-8091-43c7-a2f6-10ac0a3275d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#practice: remove one column and update csv file, the fifth column 'cell area shape area'\n",
    "  \n",
    "# read the CSV file\n",
    "# original_data = pd.read_csv('original_data.csv')\n",
    "\n",
    "# drop function which is used in removing or deleting rows or columns from the CSV files\n",
    "# original_data.drop('Cells_AreaShape_Area', inplace=True, axis=1)\n",
    "\n",
    "# print into a new csv file\n",
    "# original_data.to_csv('new_data.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f149933d-c267-4f68-a5af-95451eea6edd",
   "metadata": {},
   "source": [
    "Are we pooling all the data then correlating/removing or correlating/removing per parquet then pooling all the data?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c64cb02-597c-4afc-b597-2f81ccfeed65",
   "metadata": {},
   "source": [
    "Compute the 'correlation_matrix' which contains the pairwise correlations between numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0828a93c-2cf5-4e0e-8e51-c28bf7a20707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalize the data using the equation for robust z-transform \n",
    "\n",
    "# axis = 0 calculates the median for each column seperately\n",
    "\n",
    "numeric_df = full_df._get_numeric_data() #get numerical values only\n",
    "full_df_normalized = numeric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f73e6bf0-5101-4283-99d9-04d32fb721b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is how you would do it by hand, but it doesn't work\n",
    "\n",
    "# median = np.median(numeric_df) #take the median\n",
    "# absolute_deviation = np.abs(numeric_df - median) #take the absolute value\n",
    "# MAD = np.median(absolute_deviation) #calculate median absolute deviation \n",
    "# full_df_normalized = (0.6745 * (numeric_df - numeric_df.median(axis=0))) / MAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e625425a-ccd0-4b30-9752-1a995dd8a5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 4659)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the outliers \n",
    "\n",
    "n_MAD = 500\n",
    "threshold = 0.6745 * n_MAD\n",
    "\n",
    "# remove any columns with NaN values\n",
    "full_df_normalized = (0.6745 * (full_df_normalized- full_df_normalized.median(axis=0))) / stats.median_abs_deviation(full_df_normalized, axis=0)\n",
    "full_df_normalized = full_df_normalized.dropna(axis=1)\n",
    "# drop columns with zeros\n",
    "# full_df_normalized = full_df_normalized.loc[(full_df_normalized!=0).any(axis=1)]\n",
    "full_df_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0ef4aab-0707-4fc1-aa9a-96f8f049b88f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 4659)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_to_keep = (np.abs(full_df_normalized) < threshold).all(axis=1)\n",
    "full_df_normalized = full_df_normalized[rows_to_keep] #YOU ARE THE PROBLEM\n",
    "full_df_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "770f8abf-f8e3-4624-ad59-6781809193f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove problematic columns as per ryan's work \n",
    "# Create a boolean (T/F) array indicating which columns contain the key word\n",
    "cols_to_drop = full_df_normalized.columns[full_df_normalized.columns.str.contains('BoundingBox|Center|EulerNumber|Count|Neighbors|FormFactor|Image|Location|Overflow|mito_tubeness|Manders|MinIntensity|Cytoplasm_Texture_Contrast_DNA_10|Cytoplasm_Texture_DifferenceEntropy_DNA_10|Cytoplasm_Texture_Entropy_DNA_10|Cytoplasm_Texture_InfoMeas1_DNA_10|Cytoplasm_Texture_InfoMeas2_DNA_10|Cytoplasm_Texture_SumEntropy_DNA_10|Cytoplasm_Texture_SumVariance_DNA_10|Cytoplasm_Texture_Variance_DNA_10|CellsIncludingEdges')]\n",
    "\n",
    "full_df_normalized.drop(cols_to_drop, axis=1, inplace=True)\n",
    "# cuts slightly less columns than ryan's work\n",
    "full_df_normalized.shape\n",
    "full_df_normalized.to_csv('full_df_normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43137863-cb9f-4f3c-a738-19a20cd7c713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute the correlation matrix of numeric-only quantities with pearson correlation\n",
    "corr_matrix = full_df_normalized.corr().abs()\n",
    "# convert correlation values to a csv file\n",
    "# correlation_matrix.to_csv('correlation_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0b272200-fa32-449a-a91e-d9b45b58432b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr = DropCorrelatedFeatures(variables=None, method = 'spearman', threshold = 0.9)\n",
    "dropped_correlation = corr.fit_transform(full_df_normalized)\n",
    "# obtain the correlated feature groups that are stored in the transformerâ€™s attributes:\n",
    "groups = corr.correlated_feature_sets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "301e4a82-ac87-414c-92e9-73e5dae7e163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropped_correlation.to_csv('dropped_correlation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "3a23d2f4-9ae2-4a04-aa4d-d65f5d02ed9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "groups = sorted(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a7f6ab6b-8843-4bfa-bd36-6d1a84140476",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query you entered is position '2' in set 4\n"
     ]
    }
   ],
   "source": [
    "# Define the query \n",
    "query = 'Cytoplasm_AreaShape_Zernike_3_3'\n",
    "\n",
    "# Initialize a flag to check if the string has been found\n",
    "found = False\n",
    "position = 0\n",
    "\n",
    "# sort the appropriate set \n",
    "for i, item_set in enumerate(groups):\n",
    "    if query in item_set:\n",
    "        found = True\n",
    "        position = i\n",
    "        set_list = sorted(groups[position])\n",
    "        location = set_list.index(query)\n",
    "        print(f\"The query you entered is position '{location+1}' in set {position+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724143ba-b190-4681-a69f-16009469ffba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
